{
  "hash": "50b457650f5c82f038679f2d6d0e4081",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Feature Engineering and Selection\nexecute:\n  warning: false\n  error: false\nsidebar:\n  contents: auto\nnumber-sections: true\n---\n\n\n\n\n# Library\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ntheme_set(theme_bw())\n\nlibrary(tidymodels)  # parsnip + other tidymodels packages\nlibrary(learntidymodels)\nlibrary(embed)\n# Helper packages\nlibrary(readr)       # for importing data\nlibrary(broom.mixed) # for tidying Bayesian model output\nlibrary(dotwhisker)  # for visualizing regression results\nlibrary(skimr)       # for variable summaries\nlibrary(nycflights13)\nlibrary(ggforce)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ncolor_RUB_blue <- \"#17365c\"\ncolor_RUB_green <- \"#8dae10\"\ncolor_TUD_pink <- \"#EC008D\"\ncolor_DRESDEN <- c(\"#03305D\", \"#28618C\", \"#539DC5\", \"#84D1EE\", \"#009BA4\", \"#13A983\", \"#93C356\", \"#BCCF02\")\n```\n:::\n\n\n\n\n# Feature characteristics\n\nAt the start of the modelling process, it is essential to explore the characteristics of the available features. This step, often conducted through [Exploratory Data Analysis (EDA)](../dataprocess/eda_basic.qmd), helps to understand the distributions, relationships, and potential issues in the data before developing a model.\n\n# Encoding Categorical Variables\n\nCategorical or nominal predictors contain qualitative data. Most predictive models require numeric input and therefore cannot directly process free text or symbolic categories. These information-rich fields should be encoded into a numeric representation before being used for modelling.\n\nSimple categorical variables can be *ordered* or *unordered*.\nExamples:\n\n- Ordered: “Bad” → “Good” → “Better” (clear meaningful progression)\n- Unordered: “China”, “Germany”, “French” (no meaningful ordering)\n\nOrdered and unordered factors often require different encoding approaches.\n\nTree-based models and naive Bayes are exceptions: they can often use categories directly without explicit encoding. However, for most other model families, categorical variables must be translated into numeric form. This chapter focuses on encoding strategies.\n\nFor this exercise, we continue using the USA-Flights dataset and address the handling of the categorical variable **airport**.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_Flight <- \n  flights |> \n  mutate(\n    arr_delay = ifelse(arr_delay >= 30, \"late\", \"on_time\"),\n    arr_delay = factor(arr_delay),\n    date = lubridate::as_date(time_hour)\n  ) |> \n  inner_join(weather, by = c(\"origin\", \"time_hour\")) |> \n  select(dep_time, flight, origin, dest, air_time, distance,\n         carrier, date, arr_delay, time_hour) |> \n  na.omit() |> \n  mutate_if(is.character, as.factor)\n\nset.seed(222)  # reproducibility\n```\n:::\n\n\n\n\n## Dummy Variables for Unordered Categories\n\nThe most common way to encode categorical variables is to create dummy (one-hot) indicator variables.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrcp_Flight <- \n  recipe(arr_delay ~ ., data = df_Flight) |>    \n  step_dummy(origin)\n\nprep_Flight <- prep(rcp_Flight)\ndf_Back <- bake(prep_Flight, new_data = NULL)\n\ndata.frame(df_Flight$origin, df_Back[setdiff(names(df_Back), names(df_Flight))]) |> \n  head(100) |> \n  DT::datatable()\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"datatables html-widget html-fill-item\" id=\"htmlwidget-171579b30809a8b160d7\" style=\"width:100%;height:auto;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-171579b30809a8b160d7\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\"98\",\"99\",\"100\"],[\"EWR\",\"LGA\",\"JFK\",\"JFK\",\"LGA\",\"EWR\",\"EWR\",\"LGA\",\"JFK\",\"LGA\",\"JFK\",\"JFK\",\"JFK\",\"EWR\",\"LGA\",\"JFK\",\"EWR\",\"LGA\",\"LGA\",\"EWR\",\"LGA\",\"LGA\",\"EWR\",\"JFK\",\"EWR\",\"EWR\",\"JFK\",\"JFK\",\"JFK\",\"EWR\",\"EWR\",\"LGA\",\"LGA\",\"EWR\",\"LGA\",\"JFK\",\"JFK\",\"EWR\",\"LGA\",\"LGA\",\"EWR\",\"EWR\",\"LGA\",\"LGA\",\"JFK\",\"EWR\",\"EWR\",\"EWR\",\"JFK\",\"LGA\",\"EWR\",\"JFK\",\"JFK\",\"LGA\",\"JFK\",\"JFK\",\"LGA\",\"LGA\",\"JFK\",\"LGA\",\"EWR\",\"LGA\",\"LGA\",\"JFK\",\"LGA\",\"JFK\",\"LGA\",\"EWR\",\"EWR\",\"JFK\",\"LGA\",\"JFK\",\"JFK\",\"EWR\",\"LGA\",\"JFK\",\"EWR\",\"LGA\",\"EWR\",\"EWR\",\"EWR\",\"LGA\",\"JFK\",\"JFK\",\"LGA\",\"EWR\",\"JFK\",\"JFK\",\"LGA\",\"EWR\",\"LGA\",\"JFK\",\"JFK\",\"JFK\",\"JFK\",\"EWR\",\"EWR\",\"LGA\",\"LGA\",\"LGA\"],[0,0,1,1,0,0,0,0,1,0,1,1,1,0,0,1,0,0,0,0,0,0,0,1,0,0,1,1,1,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,1,0,0,0,1,0,0,1,1,0,1,1,0,0,1,0,0,0,0,1,0,1,0,0,0,1,0,1,1,0,0,1,0,0,0,0,0,0,1,1,0,0,1,1,0,0,0,1,1,1,1,0,0,0,0,0],[0,1,0,0,1,0,0,1,0,1,0,0,0,0,1,0,0,1,1,0,1,1,0,0,0,0,0,0,0,0,0,1,1,0,1,0,0,0,1,1,0,0,1,1,0,0,0,0,0,1,0,0,0,1,0,0,1,1,0,1,0,1,1,0,1,0,1,0,0,0,1,0,0,0,1,0,0,1,0,0,0,1,0,0,1,0,0,0,1,0,1,0,0,0,0,0,0,1,1,1]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>df_Flight.origin<\\/th>\\n      <th>origin_JFK<\\/th>\\n      <th>origin_LGA<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[2,3]},{\"orderable\":false,\"targets\":0},{\"name\":\" \",\"targets\":0},{\"name\":\"df_Flight.origin\",\"targets\":1},{\"name\":\"origin_JFK\",\"targets\":2},{\"name\":\"origin_LGA\",\"targets\":3}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n\n\n## Creating Dummy Variables for Many Categories\n\nWhen a variable has many categories (high cardinality), simple one-hot encoding becomes inefficient because it produces a very large sparse matrix.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrcp_Flight <- \n  recipe(arr_delay ~ ., data = df_Flight) |>    \n  step_dummy(dest)\n\nprep_Flight <- prep(rcp_Flight)\ndf_Back <- bake(prep_Flight, new_data = NULL)\n\ndata.frame(df_Flight$dest, df_Back[setdiff(names(df_Back), names(df_Flight))]) |> \n  head(100) |> \n  DT::datatable()\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"datatables html-widget html-fill-item\" id=\"htmlwidget-ad5906686b8cf98f2488\" style=\"width:100%;height:auto;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-ad5906686b8cf98f2488\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\"98\",\"99\",\"100\"],[\"IAH\",\"IAH\",\"MIA\",\"BQN\",\"ATL\",\"ORD\",\"FLL\",\"IAD\",\"MCO\",\"ORD\",\"PBI\",\"TPA\",\"LAX\",\"SFO\",\"DFW\",\"BOS\",\"LAS\",\"FLL\",\"ATL\",\"PBI\",\"MSP\",\"DTW\",\"MIA\",\"ATL\",\"MIA\",\"ORD\",\"SFO\",\"RSW\",\"SJU\",\"ATL\",\"PHX\",\"MIA\",\"IAH\",\"MSP\",\"MSP\",\"PHX\",\"SJU\",\"LAX\",\"ORD\",\"BWI\",\"CLT\",\"IAD\",\"DFW\",\"MCO\",\"BOS\",\"PBI\",\"CLT\",\"FLL\",\"BUF\",\"DEN\",\"SNA\",\"LAS\",\"MSY\",\"PBI\",\"SLC\",\"SFO\",\"MIA\",\"ORD\",\"MCO\",\"XNA\",\"TPA\",\"FLL\",\"ATL\",\"LAX\",\"MIA\",\"FLL\",\"DTW\",\"RSW\",\"SJU\",\"LAX\",\"ORD\",\"SJU\",\"FLL\",\"ORD\",\"MKE\",\"MCO\",\"PBI\",\"DFW\",\"SEA\",\"DFW\",\"DEN\",\"IAH\",\"SFO\",\"ROC\",\"RSW\",\"MCO\",\"SYR\",\"SFO\",\"ORD\",\"IAH\",\"TPA\",\"LAX\",\"SRQ\",\"SEA\",\"SFO\",\"SFO\",\"ORD\",\"MCO\",\"DEN\",\"CLT\"],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,1,1,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>df_Flight.dest<\\/th>\\n      <th>dest_ACK<\\/th>\\n      <th>dest_ALB<\\/th>\\n      <th>dest_ANC<\\/th>\\n      <th>dest_ATL<\\/th>\\n      <th>dest_AUS<\\/th>\\n      <th>dest_AVL<\\/th>\\n      <th>dest_BDL<\\/th>\\n      <th>dest_BGR<\\/th>\\n      <th>dest_BHM<\\/th>\\n      <th>dest_BNA<\\/th>\\n      <th>dest_BOS<\\/th>\\n      <th>dest_BQN<\\/th>\\n      <th>dest_BTV<\\/th>\\n      <th>dest_BUF<\\/th>\\n      <th>dest_BUR<\\/th>\\n      <th>dest_BWI<\\/th>\\n      <th>dest_BZN<\\/th>\\n      <th>dest_CAE<\\/th>\\n      <th>dest_CAK<\\/th>\\n      <th>dest_CHO<\\/th>\\n      <th>dest_CHS<\\/th>\\n      <th>dest_CLE<\\/th>\\n      <th>dest_CLT<\\/th>\\n      <th>dest_CMH<\\/th>\\n      <th>dest_CRW<\\/th>\\n      <th>dest_CVG<\\/th>\\n      <th>dest_DAY<\\/th>\\n      <th>dest_DCA<\\/th>\\n      <th>dest_DEN<\\/th>\\n      <th>dest_DFW<\\/th>\\n      <th>dest_DSM<\\/th>\\n      <th>dest_DTW<\\/th>\\n      <th>dest_EGE<\\/th>\\n      <th>dest_EYW<\\/th>\\n      <th>dest_FLL<\\/th>\\n      <th>dest_GRR<\\/th>\\n      <th>dest_GSO<\\/th>\\n      <th>dest_GSP<\\/th>\\n      <th>dest_HDN<\\/th>\\n      <th>dest_HNL<\\/th>\\n      <th>dest_HOU<\\/th>\\n      <th>dest_IAD<\\/th>\\n      <th>dest_IAH<\\/th>\\n      <th>dest_ILM<\\/th>\\n      <th>dest_IND<\\/th>\\n      <th>dest_JAC<\\/th>\\n      <th>dest_JAX<\\/th>\\n      <th>dest_LAS<\\/th>\\n      <th>dest_LAX<\\/th>\\n      <th>dest_LEX<\\/th>\\n      <th>dest_LGB<\\/th>\\n      <th>dest_MCI<\\/th>\\n      <th>dest_MCO<\\/th>\\n      <th>dest_MDW<\\/th>\\n      <th>dest_MEM<\\/th>\\n      <th>dest_MHT<\\/th>\\n      <th>dest_MIA<\\/th>\\n      <th>dest_MKE<\\/th>\\n      <th>dest_MSN<\\/th>\\n      <th>dest_MSP<\\/th>\\n      <th>dest_MSY<\\/th>\\n      <th>dest_MTJ<\\/th>\\n      <th>dest_MVY<\\/th>\\n      <th>dest_MYR<\\/th>\\n      <th>dest_OAK<\\/th>\\n      <th>dest_OKC<\\/th>\\n      <th>dest_OMA<\\/th>\\n      <th>dest_ORD<\\/th>\\n      <th>dest_ORF<\\/th>\\n      <th>dest_PBI<\\/th>\\n      <th>dest_PDX<\\/th>\\n      <th>dest_PHL<\\/th>\\n      <th>dest_PHX<\\/th>\\n      <th>dest_PIT<\\/th>\\n      <th>dest_PSE<\\/th>\\n      <th>dest_PSP<\\/th>\\n      <th>dest_PVD<\\/th>\\n      <th>dest_PWM<\\/th>\\n      <th>dest_RDU<\\/th>\\n      <th>dest_RIC<\\/th>\\n      <th>dest_ROC<\\/th>\\n      <th>dest_RSW<\\/th>\\n      <th>dest_SAN<\\/th>\\n      <th>dest_SAT<\\/th>\\n      <th>dest_SAV<\\/th>\\n      <th>dest_SBN<\\/th>\\n      <th>dest_SDF<\\/th>\\n      <th>dest_SEA<\\/th>\\n      <th>dest_SFO<\\/th>\\n      <th>dest_SJC<\\/th>\\n      <th>dest_SJU<\\/th>\\n      <th>dest_SLC<\\/th>\\n      <th>dest_SMF<\\/th>\\n      <th>dest_SNA<\\/th>\\n      <th>dest_SRQ<\\/th>\\n      <th>dest_STL<\\/th>\\n      <th>dest_STT<\\/th>\\n      <th>dest_SYR<\\/th>\\n      <th>dest_TPA<\\/th>\\n      <th>dest_TUL<\\/th>\\n      <th>dest_TVC<\\/th>\\n      <th>dest_TYS<\\/th>\\n      <th>dest_XNA<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104]},{\"orderable\":false,\"targets\":0},{\"name\":\" \",\"targets\":0},{\"name\":\"df_Flight.dest\",\"targets\":1},{\"name\":\"dest_ACK\",\"targets\":2},{\"name\":\"dest_ALB\",\"targets\":3},{\"name\":\"dest_ANC\",\"targets\":4},{\"name\":\"dest_ATL\",\"targets\":5},{\"name\":\"dest_AUS\",\"targets\":6},{\"name\":\"dest_AVL\",\"targets\":7},{\"name\":\"dest_BDL\",\"targets\":8},{\"name\":\"dest_BGR\",\"targets\":9},{\"name\":\"dest_BHM\",\"targets\":10},{\"name\":\"dest_BNA\",\"targets\":11},{\"name\":\"dest_BOS\",\"targets\":12},{\"name\":\"dest_BQN\",\"targets\":13},{\"name\":\"dest_BTV\",\"targets\":14},{\"name\":\"dest_BUF\",\"targets\":15},{\"name\":\"dest_BUR\",\"targets\":16},{\"name\":\"dest_BWI\",\"targets\":17},{\"name\":\"dest_BZN\",\"targets\":18},{\"name\":\"dest_CAE\",\"targets\":19},{\"name\":\"dest_CAK\",\"targets\":20},{\"name\":\"dest_CHO\",\"targets\":21},{\"name\":\"dest_CHS\",\"targets\":22},{\"name\":\"dest_CLE\",\"targets\":23},{\"name\":\"dest_CLT\",\"targets\":24},{\"name\":\"dest_CMH\",\"targets\":25},{\"name\":\"dest_CRW\",\"targets\":26},{\"name\":\"dest_CVG\",\"targets\":27},{\"name\":\"dest_DAY\",\"targets\":28},{\"name\":\"dest_DCA\",\"targets\":29},{\"name\":\"dest_DEN\",\"targets\":30},{\"name\":\"dest_DFW\",\"targets\":31},{\"name\":\"dest_DSM\",\"targets\":32},{\"name\":\"dest_DTW\",\"targets\":33},{\"name\":\"dest_EGE\",\"targets\":34},{\"name\":\"dest_EYW\",\"targets\":35},{\"name\":\"dest_FLL\",\"targets\":36},{\"name\":\"dest_GRR\",\"targets\":37},{\"name\":\"dest_GSO\",\"targets\":38},{\"name\":\"dest_GSP\",\"targets\":39},{\"name\":\"dest_HDN\",\"targets\":40},{\"name\":\"dest_HNL\",\"targets\":41},{\"name\":\"dest_HOU\",\"targets\":42},{\"name\":\"dest_IAD\",\"targets\":43},{\"name\":\"dest_IAH\",\"targets\":44},{\"name\":\"dest_ILM\",\"targets\":45},{\"name\":\"dest_IND\",\"targets\":46},{\"name\":\"dest_JAC\",\"targets\":47},{\"name\":\"dest_JAX\",\"targets\":48},{\"name\":\"dest_LAS\",\"targets\":49},{\"name\":\"dest_LAX\",\"targets\":50},{\"name\":\"dest_LEX\",\"targets\":51},{\"name\":\"dest_LGB\",\"targets\":52},{\"name\":\"dest_MCI\",\"targets\":53},{\"name\":\"dest_MCO\",\"targets\":54},{\"name\":\"dest_MDW\",\"targets\":55},{\"name\":\"dest_MEM\",\"targets\":56},{\"name\":\"dest_MHT\",\"targets\":57},{\"name\":\"dest_MIA\",\"targets\":58},{\"name\":\"dest_MKE\",\"targets\":59},{\"name\":\"dest_MSN\",\"targets\":60},{\"name\":\"dest_MSP\",\"targets\":61},{\"name\":\"dest_MSY\",\"targets\":62},{\"name\":\"dest_MTJ\",\"targets\":63},{\"name\":\"dest_MVY\",\"targets\":64},{\"name\":\"dest_MYR\",\"targets\":65},{\"name\":\"dest_OAK\",\"targets\":66},{\"name\":\"dest_OKC\",\"targets\":67},{\"name\":\"dest_OMA\",\"targets\":68},{\"name\":\"dest_ORD\",\"targets\":69},{\"name\":\"dest_ORF\",\"targets\":70},{\"name\":\"dest_PBI\",\"targets\":71},{\"name\":\"dest_PDX\",\"targets\":72},{\"name\":\"dest_PHL\",\"targets\":73},{\"name\":\"dest_PHX\",\"targets\":74},{\"name\":\"dest_PIT\",\"targets\":75},{\"name\":\"dest_PSE\",\"targets\":76},{\"name\":\"dest_PSP\",\"targets\":77},{\"name\":\"dest_PVD\",\"targets\":78},{\"name\":\"dest_PWM\",\"targets\":79},{\"name\":\"dest_RDU\",\"targets\":80},{\"name\":\"dest_RIC\",\"targets\":81},{\"name\":\"dest_ROC\",\"targets\":82},{\"name\":\"dest_RSW\",\"targets\":83},{\"name\":\"dest_SAN\",\"targets\":84},{\"name\":\"dest_SAT\",\"targets\":85},{\"name\":\"dest_SAV\",\"targets\":86},{\"name\":\"dest_SBN\",\"targets\":87},{\"name\":\"dest_SDF\",\"targets\":88},{\"name\":\"dest_SEA\",\"targets\":89},{\"name\":\"dest_SFO\",\"targets\":90},{\"name\":\"dest_SJC\",\"targets\":91},{\"name\":\"dest_SJU\",\"targets\":92},{\"name\":\"dest_SLC\",\"targets\":93},{\"name\":\"dest_SMF\",\"targets\":94},{\"name\":\"dest_SNA\",\"targets\":95},{\"name\":\"dest_SRQ\",\"targets\":96},{\"name\":\"dest_STL\",\"targets\":97},{\"name\":\"dest_STT\",\"targets\":98},{\"name\":\"dest_SYR\",\"targets\":99},{\"name\":\"dest_TPA\",\"targets\":100},{\"name\":\"dest_TUL\",\"targets\":101},{\"name\":\"dest_TVC\",\"targets\":102},{\"name\":\"dest_TYS\",\"targets\":103},{\"name\":\"dest_XNA\",\"targets\":104}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n\n\nA better approach for high-cardinality variables is *hash encoding*:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrcp_Flight <- \n  recipe(arr_delay ~ ., data = df_Flight) |>    \n  textrecipes::step_dummy_hash(dest, num_terms = 16)\n\nprep_Flight <- prep(rcp_Flight)\ndf_Back <- bake(prep_Flight, new_data = NULL)\n\ndata.frame(df_Flight$dest, df_Back[setdiff(names(df_Back), names(df_Flight))]) |> \n  head(100) |> \n  DT::datatable()\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"datatables html-widget html-fill-item\" id=\"htmlwidget-c00495ef682a08bfcfc4\" style=\"width:100%;height:auto;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-c00495ef682a08bfcfc4\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\"98\",\"99\",\"100\"],[\"IAH\",\"IAH\",\"MIA\",\"BQN\",\"ATL\",\"ORD\",\"FLL\",\"IAD\",\"MCO\",\"ORD\",\"PBI\",\"TPA\",\"LAX\",\"SFO\",\"DFW\",\"BOS\",\"LAS\",\"FLL\",\"ATL\",\"PBI\",\"MSP\",\"DTW\",\"MIA\",\"ATL\",\"MIA\",\"ORD\",\"SFO\",\"RSW\",\"SJU\",\"ATL\",\"PHX\",\"MIA\",\"IAH\",\"MSP\",\"MSP\",\"PHX\",\"SJU\",\"LAX\",\"ORD\",\"BWI\",\"CLT\",\"IAD\",\"DFW\",\"MCO\",\"BOS\",\"PBI\",\"CLT\",\"FLL\",\"BUF\",\"DEN\",\"SNA\",\"LAS\",\"MSY\",\"PBI\",\"SLC\",\"SFO\",\"MIA\",\"ORD\",\"MCO\",\"XNA\",\"TPA\",\"FLL\",\"ATL\",\"LAX\",\"MIA\",\"FLL\",\"DTW\",\"RSW\",\"SJU\",\"LAX\",\"ORD\",\"SJU\",\"FLL\",\"ORD\",\"MKE\",\"MCO\",\"PBI\",\"DFW\",\"SEA\",\"DFW\",\"DEN\",\"IAH\",\"SFO\",\"ROC\",\"RSW\",\"MCO\",\"SYR\",\"SFO\",\"ORD\",\"IAH\",\"TPA\",\"LAX\",\"SRQ\",\"SEA\",\"SFO\",\"SFO\",\"ORD\",\"MCO\",\"DEN\",\"CLT\"],[1,1,0,0,0,0,0,-1,0,0,0,0,0,0,0,0,-1,0,0,0,0,0,0,0,0,0,0,0,-1,0,0,0,1,0,0,0,-1,0,0,0,0,-1,0,0,0,0,0,0,0,-1,0,-1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-1,0,0,-1,0,0,1,0,0,0,0,0,-1,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,-1,0],[0,0,0,0,0,-1,0,0,0,-1,0,0,0,0,0,0,0,0,0,0,0,-1,0,0,0,-1,0,0,0,0,0,0,0,0,0,0,0,0,-1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-1,0,0,0,0,0,0,0,0,-1,0,0,0,-1,0,0,-1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,-1,0,0,0,0,1,0,0,-1,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,-1,0,0,0,0,0,0,0,0,-1,0,0,0,0,-1,0,0,0,0,-1,0,0,-1,0,0,-1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-1,0,0,0,0,0,0,-1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-1,0,0,0,0,-1,0,0,0,0,0,0,-1,-1,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,-1,0,0,0,1,0,0,0,0,0,0,-1,0,1,0,0,0,0,0,0,0,0,0,0,-1,0,0,0,0,-1,0,0,0,0,0,0,0,0,0,1,0,-1,0,0,0,0,0,1,0,0,0,0,0,0,0,-1,0,0,0,-1,0,0,0,0,0,0,-1,0,0,0,1,0,0,0,0,0,0,0,0,0,-1,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-1,0,0,0,0,0,0,0,0,0,0,0,0,-1,-1,0,0,0,0,0,-1,0,0,0,0,0,-1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-1],[0,0,0,0,0,0,0,0,1,0,0,1,-1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-1,0,0,0,0,0,0,0,0,0,-1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,-1,0,0,0,0,0,1,0,1,0,0,-1,0,0,0,-1,0,-1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,-1,1,0,0,0,0,1,-1,0,0,0,0,0,1,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,-1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0],[0,0,0,-1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>df_Flight.dest<\\/th>\\n      <th>dummyhash_dest_01<\\/th>\\n      <th>dummyhash_dest_02<\\/th>\\n      <th>dummyhash_dest_03<\\/th>\\n      <th>dummyhash_dest_04<\\/th>\\n      <th>dummyhash_dest_05<\\/th>\\n      <th>dummyhash_dest_06<\\/th>\\n      <th>dummyhash_dest_07<\\/th>\\n      <th>dummyhash_dest_08<\\/th>\\n      <th>dummyhash_dest_09<\\/th>\\n      <th>dummyhash_dest_10<\\/th>\\n      <th>dummyhash_dest_11<\\/th>\\n      <th>dummyhash_dest_12<\\/th>\\n      <th>dummyhash_dest_13<\\/th>\\n      <th>dummyhash_dest_14<\\/th>\\n      <th>dummyhash_dest_15<\\/th>\\n      <th>dummyhash_dest_16<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17]},{\"orderable\":false,\"targets\":0},{\"name\":\" \",\"targets\":0},{\"name\":\"df_Flight.dest\",\"targets\":1},{\"name\":\"dummyhash_dest_01\",\"targets\":2},{\"name\":\"dummyhash_dest_02\",\"targets\":3},{\"name\":\"dummyhash_dest_03\",\"targets\":4},{\"name\":\"dummyhash_dest_04\",\"targets\":5},{\"name\":\"dummyhash_dest_05\",\"targets\":6},{\"name\":\"dummyhash_dest_06\",\"targets\":7},{\"name\":\"dummyhash_dest_07\",\"targets\":8},{\"name\":\"dummyhash_dest_08\",\"targets\":9},{\"name\":\"dummyhash_dest_09\",\"targets\":10},{\"name\":\"dummyhash_dest_10\",\"targets\":11},{\"name\":\"dummyhash_dest_11\",\"targets\":12},{\"name\":\"dummyhash_dest_12\",\"targets\":13},{\"name\":\"dummyhash_dest_13\",\"targets\":14},{\"name\":\"dummyhash_dest_14\",\"targets\":15},{\"name\":\"dummyhash_dest_15\",\"targets\":16},{\"name\":\"dummyhash_dest_16\",\"targets\":17}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n\n\nHash encoding maps categorical levels to a fixed number of numerical features using a hashing function. Instead of creating one column per category, each category is transformed into a set of hashed feature values.\n\nAdvantages:\n\n- Produces a fixed feature dimensionality through `num_terms`\n- Scales well to hundreds or thousands of categories\n- Automatically handles unseen categories at prediction time\n- Avoids imposing artificial ordering (unlike integer encoding)\n- More memory-efficient than one-hot encoding for large category sets\n- Works directly on character/factor variables without additional preprocessing\n\nDisadvantages:\n\n- Hash collisions may occur, causing different categories to map to the same bucket\n- Features are not interpretable because the mapping is not reversible\n- Collisions can degrade accuracy, especially for models sensitive to feature distortions (e.g., linear models)\n- Choosing an appropriate value for `num_terms` is heuristic and problem-dependent\n- Not advantageous for low-cardinality variables\n\n\n\n\n\n## Approaches for Novel Categories\n\nIn practical applications, test data often contain categories not seen during training.\nRecipes includes a dedicated step for this:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrcp_Flight <- \n  recipe(arr_delay ~ ., data = df_Flight) |>    \n  step_novel() |> \n  step_dummy(origin)\n\nprep_Flight <- prep(rcp_Flight)\ndf_Back <- bake(prep_Flight, new_data = NULL)\n\ndata.frame(df_Flight$origin, df_Back[setdiff(names(df_Back), names(df_Flight))]) |> \n  head(100) |> DT::datatable()\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"datatables html-widget html-fill-item\" id=\"htmlwidget-65c3344db1262524ae00\" style=\"width:100%;height:auto;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-65c3344db1262524ae00\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\"98\",\"99\",\"100\"],[\"EWR\",\"LGA\",\"JFK\",\"JFK\",\"LGA\",\"EWR\",\"EWR\",\"LGA\",\"JFK\",\"LGA\",\"JFK\",\"JFK\",\"JFK\",\"EWR\",\"LGA\",\"JFK\",\"EWR\",\"LGA\",\"LGA\",\"EWR\",\"LGA\",\"LGA\",\"EWR\",\"JFK\",\"EWR\",\"EWR\",\"JFK\",\"JFK\",\"JFK\",\"EWR\",\"EWR\",\"LGA\",\"LGA\",\"EWR\",\"LGA\",\"JFK\",\"JFK\",\"EWR\",\"LGA\",\"LGA\",\"EWR\",\"EWR\",\"LGA\",\"LGA\",\"JFK\",\"EWR\",\"EWR\",\"EWR\",\"JFK\",\"LGA\",\"EWR\",\"JFK\",\"JFK\",\"LGA\",\"JFK\",\"JFK\",\"LGA\",\"LGA\",\"JFK\",\"LGA\",\"EWR\",\"LGA\",\"LGA\",\"JFK\",\"LGA\",\"JFK\",\"LGA\",\"EWR\",\"EWR\",\"JFK\",\"LGA\",\"JFK\",\"JFK\",\"EWR\",\"LGA\",\"JFK\",\"EWR\",\"LGA\",\"EWR\",\"EWR\",\"EWR\",\"LGA\",\"JFK\",\"JFK\",\"LGA\",\"EWR\",\"JFK\",\"JFK\",\"LGA\",\"EWR\",\"LGA\",\"JFK\",\"JFK\",\"JFK\",\"JFK\",\"EWR\",\"EWR\",\"LGA\",\"LGA\",\"LGA\"],[0,0,1,1,0,0,0,0,1,0,1,1,1,0,0,1,0,0,0,0,0,0,0,1,0,0,1,1,1,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,1,0,0,0,1,0,0,1,1,0,1,1,0,0,1,0,0,0,0,1,0,1,0,0,0,1,0,1,1,0,0,1,0,0,0,0,0,0,1,1,0,0,1,1,0,0,0,1,1,1,1,0,0,0,0,0],[0,1,0,0,1,0,0,1,0,1,0,0,0,0,1,0,0,1,1,0,1,1,0,0,0,0,0,0,0,0,0,1,1,0,1,0,0,0,1,1,0,0,1,1,0,0,0,0,0,1,0,0,0,1,0,0,1,1,0,1,0,1,1,0,1,0,1,0,0,0,1,0,0,0,1,0,0,1,0,0,0,1,0,0,1,0,0,0,1,0,1,0,0,0,0,0,0,1,1,1]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>df_Flight.origin<\\/th>\\n      <th>origin_JFK<\\/th>\\n      <th>origin_LGA<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[2,3]},{\"orderable\":false,\"targets\":0},{\"name\":\" \",\"targets\":0},{\"name\":\"df_Flight.origin\",\"targets\":1},{\"name\":\"origin_JFK\",\"targets\":2},{\"name\":\"origin_LGA\",\"targets\":3}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n\n\n`step_novel()` must come *before* `step_dummy()` so that the training step learns the “new” category and creates a corresponding column.\nThis does not improve prediction performance—it only prevents errors.\n\n## Encodings for Ordered Data\n\nFor ordinal categories (e.g., *bad < normal < good* or *low < medium < high*), the ordering contains useful information.\n\nPossible numeric encodings:\n\n* Linear integer encoding (e.g. -1, 0, 1) → `step_integer`\n* Polynomial or contrast encodings → `step_poly`\n* Multiple orthogonal encodings to capture more structure\n\n## Knowledge-based Mapping\n\nSometimes a categorical variable corresponds to a meaningful numeric attribute.\nYou can encode the category directly using domain knowledge.\n\nExamples:\n\n* Plant species → root depth\n* Weather condition (sunny, cloudy, rain) → sunshine hours\n\nThis requires a lookup table and domain understanding, so there is no universal function. You can simply use a join:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_Main <- tibble(\n  id = 1:6,\n  plant_type = c(\"Wheat\", \"Corn\", \"Soybean\", \"Wheat\", \"Corn\", \"Rice\")\n)\n\ndf_AttriTable <- tibble(\n  plant_type = c(\"Wheat\", \"Corn\", \"Soybean\", \"Rice\"),\n  root_depth_cm = c(120, 150, 80, 130)\n)\n\ndf_Main |> \n  left_join(df_AttriTable, by = \"plant_type\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n     id plant_type root_depth_cm\n  <int> <chr>              <dbl>\n1     1 Wheat                120\n2     2 Corn                 150\n3     3 Soybean               80\n4     4 Wheat                120\n5     5 Corn                 150\n6     6 Rice                 130\n```\n\n\n:::\n:::\n\n\n\n\n\n# Numeric Feature Engineering\n\nNumeric features often present challenges when their distributions are highly skewed, contain outliers, or span very different ranges. While tree-based models are generally robust to such issues, many other algorithms (e.g., generalized linear models, regularized regression, k-nearest neighbors, support vector machines, and neural networks) can be adversely affected. Reducing skewness and standardizing the scale of features can substantially improve model performance. Transformations that reshape distributions and scaling methods such as standardization or normalization are therefore essential components of preprocessing workflows (Boehmke & Greenwell, 2019).\n\n## Distribution-shaping Transformations\n\nIn some variables, most values cluster within a very narrow range or display strong deviations from a normal-like distribution. Such skewed or compressed distributions may limit model performance. Similar to target transformation, applying transformations to minimize skewness in predictors can improve model fit. Box–Cox (`step_BoxCox`) and Yeo–Johnson (`step_YeoJohnson`) are commonly used approaches, although classical options such as logarithmic or square-root transformations also remain effective.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_Bochum_KL <- read_csv(\"../data_share/df_Bochum_KL.csv\")\ndf_FeatureEng <- df_Bochum_KL[,c(\"evapo_r\", \"evapo_p\", \"RSK\", \"soil_moist\")]\nggplot_hist <- function(df_Data) {\n  df_long <- df_Data |>\n    pivot_longer(\n      cols = everything(),     # all columns; or select specific columns\n      names_to = \"variable\",\n      values_to = \"value\"\n    )\n  \n  # Plot faceted histograms\n  ggplot(df_long, aes(x = value)) +\n    geom_histogram(bins = 30, fill = color_RUB_green, color = color_RUB_blue) +\n    facet_wrap(~ variable, scales = \"free\") +\n    labs(x = \"Value\", y = \"Frequency\") +\n    theme(axis.text.y = element_text(angle = 90, vjust = 0.5, hjust = 0.5))\n}\ngp_Ori <- ggplot_hist(df_FeatureEng[,c(\"evapo_p\", \"RSK\", \"soil_moist\")])\ngp_Ori\n```\n\n::: {.cell-output-display}\n![](ml_feature_engineering_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n\n\n### Yeo–Johnson Transformation\nA flexible transformation that accommodates positive, zero, and negative values.\n\n**Formula**  \nFor a value $ x $ and transformation parameter $ \\lambda $:\n\n$$\nT(x;\\lambda) =\n\\begin{cases}\n\\frac{(x+1)^{\\lambda}-1}{\\lambda}, & x \\ge 0,\\ \\lambda \\ne 0 \\\\\n\\ln(x+1), & x \\ge 0,\\ \\lambda = 0 \\\\\n-\\frac{(1-x)^{2-\\lambda}-1}{2-\\lambda}, & x < 0,\\ \\lambda \\ne 2 \\\\\n-\\ln(1-x), & x < 0,\\ \\lambda = 2\n\\end{cases}\n$$\n\n**Properties**\n- Works with positive, zero, and negative values.\n- Estimates the parameter $ \\lambda $ to reduce skewness.\n- Often yields distributions closest to normality.\n- Less interpretable and slightly slower due to parameter estimation.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrcp_YeoJohnson <- recipe(evapo_r ~ ., data = df_FeatureEng) |>\n  step_YeoJohnson(all_predictors())   # handles zeros and negatives\ndf_YeoJohnson <- prep(rcp_YeoJohnson) |> bake(new_data = NULL)\ngp_YeoJohnson <- ggplot_hist(df_YeoJohnson[,c(\"evapo_p\", \"RSK\", \"soil_moist\")])\ngp_YeoJohnson\n```\n\n::: {.cell-output-display}\n![](ml_feature_engineering_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n### Logarithmic Transformation\nA strong transformation for right-skewed positive variables.\n\n**Formula**\n\n$$\nT(x) = \\log(x)\n$$\n\n**Properties**\n- Only defined for strictly positive values.\n- Suitable for multiplicative processes and highly right-skewed data.\n- Strongly compresses large values.\n- Not applicable to zero or negative values.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrcp_Log <- recipe(evapo_r ~ ., data = df_FeatureEng) |>\n  step_mutate(across(all_predictors(), ~ .x - min(.x) + 1e-6)) |>\n  step_log(all_predictors())\ndf_Log <- prep(rcp_Log) |> bake(new_data = NULL)\ngp_Log <- ggplot_hist(df_Log[,c(\"evapo_p\", \"RSK\", \"soil_moist\")])\ngp_Log\n```\n\n::: {.cell-output-display}\n![](ml_feature_engineering_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\n\n\n### Square-Root Transformation\nA mild transformation suitable for non-negative, moderately right-skewed data.\n\n**Formula**\n\n$$\nT(x) = \\sqrt{x}\n$$\n\n**Properties**\n- Defined for zero and positive values.\n- Less aggressive than the log transformation.\n- Reduces right-skewness but insufficient for heavy skewness.\n- Not applicable to negative values.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrcp_Sqrt <- recipe(evapo_r ~ ., data = df_FeatureEng) |>\n  step_mutate(across(all_predictors(), ~ .x - min(.x) + 1e-6)) |>\n  step_sqrt(all_predictors())\ndf_Sqrt <- prep(rcp_Sqrt) |> bake(new_data = NULL)\ngp_Sqrt <- ggplot_hist(df_Sqrt[,c(\"evapo_p\", \"RSK\", \"soil_moist\")])\ngp_Sqrt\n```\n\n::: {.cell-output-display}\n![](ml_feature_engineering_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n\n\n\n### Choosing a Transformation\n\n- Right-skewed and strictly positive → **Log**\n- Right-skewed and non-negative → **Square-root**\n- Mixed signs or unclear skewness → **Yeo–Johnson**\n\n## Standardization and Normalization\n\nScaling features to comparable magnitudes is crucial for algorithms that rely on linear functions or distance metrics, such as regression models, neural networks, support vector machines, k-means, and hierarchical clustering.\n\n### Standardization (Z-Scaling)\nCenters each feature at zero mean and scales to unit variance.\n\n**Formula**\n\n$$\nz = \\frac{x - \\mu}{\\sigma}\n$$\n\nwhere  \n$\\mu$ = mean of the feature,  \n$\\sigma$ = standard deviation.\n\n**Properties**\n- Produces features with mean 0 and standard deviation 1.\n- Preserves distribution shape and skewness.\n- Outliers still influence the scale.\n- Widely used for algorithms assuming normal-like distributions.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrcp_Normal <- recipe(evapo_r ~ ., data = df_FeatureEng) |>\n  step_normalize(all_predictors())    # (x − mean) / sd\ndf_Normal <- prep(rcp_Normal) |> bake(new_data = NULL)\ngp_Normal <- ggplot_hist(df_Normal[,c(\"evapo_p\", \"RSK\", \"soil_moist\")])\ngp_Normal\n```\n\n::: {.cell-output-display}\n![](ml_feature_engineering_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n\n\n\n### Normalization (Min–Max Scaling)\nRescales each feature to the interval $[0, 1]$.\n\n**Formula**\n\n$$\nx' = \\frac{x - x_{\\min}}{x_{\\max} - x_{\\min}}\n$$\n\n**Properties**\n- Compresses all values into a fixed range.\n- Highly sensitive to outliers.\n- Preserves relative ordering but not distributional shape.\n- Useful when absolute scales matter or when features must lie in $[0,1]$, such as in neural networks and kNN.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrcp_MinMax <- recipe(evapo_r ~ ., data = df_FeatureEng)  |> \n  step_range(all_predictors())\ndf_MinMax <- prep(rcp_MinMax) |> bake(new_data = NULL)\ngp_MinMax <- ggplot_hist(df_MinMax[,c(\"evapo_p\", \"RSK\", \"soil_moist\")])\ngp_MinMax\n```\n\n::: {.cell-output-display}\n![](ml_feature_engineering_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n\n\n### Choosing a Scaling Method\n\nUse **standardization** when  \n- variables need equal weight,  \n- algorithms assume normally scaled inputs,  \n- outliers should not dominate the scaling range.\n\nUse **normalization** when  \n- features must lie within $[0,1]$,  \n- distance-based methods or neural networks are used,  \n- absolute ranges are important.\n\n\n# Feature Selection\n\nMotivations for feature selection [@FeatureEngin_Johnson_2019] include:\n\n\n- Some models, notably support vector machines and neural networks, are sensitive to irrelevant predictors. As will be shown below, superfluous predictors can sink predictive performance in some situations.\n\n- Other models like linear or logistic regression are vulnerable to correlated predictors (see Chapter 6). Removing correlated predictors will reduce multicollinearity and thus enable these types of models to be fit.\n\n- Even when a predictive model is insensitive to extra predictors, it makes good scientific sense to include the minimum possible set that provides acceptable results. In some cases, removing predictors can reduce the cost of acquiring data or improve the throughput of the software used to make predictions.\n\n\n\nThis feature selection process is closely tied to model tuning and will be addressed in detail in the next course.\n\n\n\n# Dimension reduction\n\n\n\nDimension reduction is an alternative approach to filter out non-informative features without manually removing them.\n\n## Principal Components Analysis\n\nPrincipal components analysis (PCA) is a method for finding low-dimensional representations of a data set that retain as much of the original variation as possible. \n\n\nThe idea is that each of the n observations lives in p-dimensional space, but not all of these dimensions are equally interesting. In PCA we look for a smaller number of dimensions that are as interesting as possible, where the concept of interesting is measured by the amount that the observations vary along each dimension.\n\n\nFor Principal Component Analysis (PCA), the first step is to decide how many dimensions (principal components) to retain. A common approach is to base this decision on the **eigenvalues** of the principal components:\n\n1. **Eigenvalue threshold criterion:** Retain components with eigenvalues greater than 1. This approach assumes that any component accounting for more variance than an individual original variable is worth keeping.\n\n2. **Cumulative variance explained criterion:** Retain enough components to explain a desired proportion of the total variance, such as 75% or 90%. This allows the analyst to select the minimum number of components that capture a substantial fraction of the original data's variability. Metrics such as **Proportion of Variance Explained (PVE)** or **Cumulative Variance Explained (CVE)** are commonly used for this purpose.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrcp_NormalAll <- recipe(evapo_r ~ ., data = df_Bochum_KL) |>\n  step_normalize(all_predictors())\ndf_NormalAll <- prep(rcp_NormalAll) |> bake(new_data = NULL)\n\npca_Noraml <- prcomp(df_NormalAll |> select(-evapo_r), scale = FALSE)\neigen_Normal <- pca_Noraml$sdev^2\n\nggplot() +\n  geom_point(aes(x = 1:length(eigen_Normal), y = eigen_Normal)) +\n  geom_hline(yintercept = 1, linetype = \"dashed\", color = color_TUD_pink) +\n  labs(x = \"PC\", y = \"Eigenvalue\")\n```\n\n::: {.cell-output-display}\n![](ml_feature_engineering_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnum_CVE <- cumsum(eigen_Normal / sum(eigen_Normal))\nggplot() +\n  geom_line(aes(x = 1:length(num_CVE), y = num_CVE), color = color_RUB_green) +\n  geom_point(aes(x = 1:length(num_CVE), y = num_CVE), color = color_RUB_green) +\n  geom_hline(yintercept = .9, linetype = \"dashed\", color = color_TUD_pink) +\n  labs(x = \"PC\", y = \"CVE\")\n```\n\n::: {.cell-output-display}\n![](ml_feature_engineering_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n\n\n\n- Set the number of principal components (PCs) manually\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrcp_PCA4 <- recipe(evapo_r ~ ., data = df_Bochum_KL) |>\n  step_normalize(all_predictors()) |>\n  step_pca(all_predictors(), num_comp = 4)\ndf_PCA4 <- prep(rcp_PCA4) |> bake(new_data = NULL)\n```\n:::\n\n\n\n\n- Set the percentage of variability in the variables\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrcp_PCA75per <- recipe(evapo_r ~ ., data = df_Bochum_KL) |>\n  step_normalize(all_predictors()) |> \n  step_pca(all_predictors(), threshold = .75)\n\ndf_PCA75per <- prep(rcp_PCA75per) |> bake(new_data = NULL)\n```\n:::\n\n::: {.cell fig-fullwidth='true'}\n\n```{.r .cell-code}\nggplot(df_PCA4, aes(x = .panel_x, y = .panel_y, color = evapo_r, fill = evapo_r)) +\n  geom_point(size = 0.5) +\n  geom_autodensity(alpha = .8, fill = color_RUB_green, color = color_RUB_blue) +\n  facet_matrix(vars(-evapo_r), layer.diag = 2) + \n  scale_color_gradientn(colors = color_DRESDEN) + \n  scale_fill_gradientn(colors = color_DRESDEN)\n```\n\n::: {.cell-output-display}\n![](ml_feature_engineering_files/figure-html/unnamed-chunk-19-1.png){width=960}\n:::\n:::\n\n::: {.cell fig-fullwidth='true'}\n\n```{.r .cell-code}\nplot_top_loadings(\n  prep(rcp_PCA4),\n  component_number <= 4,\n  n = 4,               # number of variables to show per PC\n  type = \"pca\"    # which PCs to plot\n) +\n  scale_fill_manual(values = c(\"TRUE\" = color_RUB_green, \"FALSE\" = color_RUB_blue))+\n  theme(legend.position = \"inside\",\n        legend.position.inside = c(.99, .01),\n        legend.justification = c(1,0))\n```\n\n::: {.cell-output-display}\n![](ml_feature_engineering_files/figure-html/unnamed-chunk-20-1.png){width=960}\n:::\n:::\n\n\n\n\n\n\n## Independent Component Analysis (ICA)\n\nIndependent Component Analysis (ICA) is a **dimension reduction** technique that seeks to represent multivariate data as a combination of statistically independent components. Unlike methods such as Principal Component Analysis (PCA), which maximize variance and produce uncorrelated components, ICA focuses on identifying **underlying latent factors that are mutually independent**. \n\n\n\n\n\n\n::: {.cell fig-fullwidth='true'}\n\n```{.r .cell-code}\nrcp_ICA4 <- recipe(evapo_r ~ ., data = df_Bochum_KL) |>\n  step_normalize(all_predictors()) |>\n  step_ica(all_predictors(), num_comp = 4)\ndf_ICA4 <- prep(rcp_ICA4) |> bake(new_data = NULL)\n\nggplot(df_ICA4, aes(x = .panel_x, y = .panel_y, color = evapo_r, fill = evapo_r)) +\n  geom_point(size = 0.5) +\n  geom_autodensity(alpha = .8, fill = color_RUB_green, color = color_RUB_blue) +\n  facet_matrix(vars(-evapo_r), layer.diag = 2) + \n  scale_color_gradientn(colors = color_DRESDEN) + \n  scale_fill_gradientn(colors = color_DRESDEN)\n```\n\n::: {.cell-output-display}\n![](ml_feature_engineering_files/figure-html/unnamed-chunk-21-1.png){width=960}\n:::\n:::\n\n::: {.cell fig-fullwidth='true'}\n\n```{.r .cell-code}\nplot_top_loadings(\n  prep(rcp_ICA4),\n  component_number <= 4,\n  n = 4,               # number of variables to show per PC\n  type = \"ica\"    # which PCs to plot\n) +\n  scale_fill_manual(values = c(\"TRUE\" = color_RUB_green, \"FALSE\" = color_RUB_blue))+\n  theme(legend.position = \"inside\",\n        legend.position.inside = c(.99, .01),\n        legend.justification = c(1,0))\n```\n\n::: {.cell-output-display}\n![](ml_feature_engineering_files/figure-html/unnamed-chunk-22-1.png){width=960}\n:::\n:::\n\n\n\n\n## Uniform Manifold Approximation and Projection (UMAP)\n\nUniform Manifold Approximation and Projection (UMAP) is a **nonlinear dimension reduction** technique designed to project high-dimensional data into a lower-dimensional space while preserving its intrinsic geometric structure. UMAP is particularly effective at maintaining both local relationships (i.e., neighborhood structure) and global patterns in the data. Unlike linear methods such as PCA, UMAP can capture complex, nonlinear structures in the data, making it well-suited for high-dimensional datasets with intricate patterns.\n\n\n\n\n\n::: {.cell fig-fullwidth='true'}\n\n```{.r .cell-code}\nrcp_UMAP4 <- recipe(evapo_r ~ ., data = df_Bochum_KL) |>\n  step_normalize(all_predictors()) |>\n  step_umap(all_predictors(), num_comp = 4)\ndf_UMAP4 <- prep(rcp_UMAP4) |> bake(new_data = NULL)\n\nggplot(df_UMAP4, aes(x = .panel_x, y = .panel_y, color = evapo_r, fill = evapo_r)) +\n  geom_point(size = 0.5) +\n  geom_autodensity(alpha = .8, fill = color_RUB_green, color = color_RUB_blue) +\n  facet_matrix(vars(-evapo_r), layer.diag = 2) + \n  scale_color_gradientn(colors = color_DRESDEN) + \n  scale_fill_gradientn(colors = color_DRESDEN)\n```\n\n::: {.cell-output-display}\n![](ml_feature_engineering_files/figure-html/unnamed-chunk-23-1.png){width=960}\n:::\n:::\n\n\n\n\n\n## Generalized Low Rank Models (GLRM)\n\nGeneralized Low Rank Models (GLRM) is a generalization of PCA and matrix factorization, which is more flexibel and useable for categorei variables. The the orginal variables iwll replace by a dimesnionreduced matrix X, which $A = X \\times Y$. This approach is not aviable in `recipes` framework and more complex, so we do not give a excies. more details is in [https://bradleyboehmke.github.io/HOML/GLRM.html](https://bradleyboehmke.github.io/HOML/GLRM.html) aviable\n\n\n\n# Time and spatial dimension\n\nIn exploratory data analysis (EDA), we usually invest substantial effort in preparing temporal and spatial features. Actually, the `recipes` framework also provides several useful steps for handling these data.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_TimeSpat <- data.frame(\n  id = 1:10,\n  lat = c(52.52, 48.85, 51.51, 40.71, 34.05, 35.68, 55.75, 37.77, 41.90, 59.33),\n  lon = c(13.40, 2.35, -0.13, -74.01, -118.25, 139.69, 37.62, -122.42, 12.49, 18.07),\n  date = seq.Date(from = as.Date(\"2025-01-01\"), by = \"day\", length.out = 10),\n  target = rnorm(10, 100, 10)\n)\n```\n:::\n\n\n\n\n\n## Distance\n\nComputing the distance to a reference point is often helpful in spatial-related datasheet.\nWith `recipes`, this can be achieved using steps such as `step_geodist`, allowing us to transform coordinates (e.g., latitude/longitude) into meaningful spatial distance features.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec_TimeSpat <- recipe(target ~ ., data = df_TimeSpat)  |> \n  step_geodist(lat, lon, ref_lat = 52.52, ref_lon = 13.40, name = \"dist_to_berlin\")\nbake(prep(rec_TimeSpat), new_data = df_TimeSpat) |> head(100) |> DT::datatable()\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"datatables html-widget html-fill-item\" id=\"htmlwidget-4eda5c5566edbd563eb3\" style=\"width:100%;height:auto;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-4eda5c5566edbd563eb3\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"],[1,2,3,4,5,6,7,8,9,10],[52.52,48.85,51.51,40.71,34.05,35.68,55.75,37.77,41.9,59.33],[13.4,2.35,-0.13,-74.01000000000001,-118.25,139.69,37.62,-122.42,12.49,18.07],[\"2025-01-01\",\"2025-01-02\",\"2025-01-03\",\"2025-01-04\",\"2025-01-05\",\"2025-01-06\",\"2025-01-07\",\"2025-01-08\",\"2025-01-09\",\"2025-01-10\"],[112.3114467678052,107.8921549245735,107.4884504805814,100.5747646401079,108.4295052693808,101.9985915359134,114.5117130990463,95.39840021619115,72.25533089682037,100.5648900937107],[0,877676.5273077731,931318.778737352,6385158.411298048,9309947.633787204,8917170.301569173,1609281.287031406,9105532.551588202,1182863.177360424,810721.5835619495]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>id<\\/th>\\n      <th>lat<\\/th>\\n      <th>lon<\\/th>\\n      <th>date<\\/th>\\n      <th>target<\\/th>\\n      <th>dist_to_berlin<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,2,3,5,6]},{\"orderable\":false,\"targets\":0},{\"name\":\" \",\"targets\":0},{\"name\":\"id\",\"targets\":1},{\"name\":\"lat\",\"targets\":2},{\"name\":\"lon\",\"targets\":3},{\"name\":\"date\",\"targets\":4},{\"name\":\"target\",\"targets\":5},{\"name\":\"dist_to_berlin\",\"targets\":6}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n\n\n## Date and holiday\n\nDate variables can be expanded into more informative features such as weekday, weekend, month, or season.\nAdditionally, holiday signatures can be added to capture special events or non-working days.\nRecipes provides steps like `step_date` and time-series extensions such as `step_holiday`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec_TimeSpat <- recipe(target ~ ., data = df_TimeSpat)  |> \n  step_date(date) |> \n  step_holiday(date)\nbake(prep(rec_TimeSpat), new_data = df_TimeSpat) |> head(100) |> DT::datatable()\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"datatables html-widget html-fill-item\" id=\"htmlwidget-1bdd838b79f3561df329\" style=\"width:100%;height:auto;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-1bdd838b79f3561df329\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"],[1,2,3,4,5,6,7,8,9,10],[52.52,48.85,51.51,40.71,34.05,35.68,55.75,37.77,41.9,59.33],[13.4,2.35,-0.13,-74.01000000000001,-118.25,139.69,37.62,-122.42,12.49,18.07],[\"2025-01-01\",\"2025-01-02\",\"2025-01-03\",\"2025-01-04\",\"2025-01-05\",\"2025-01-06\",\"2025-01-07\",\"2025-01-08\",\"2025-01-09\",\"2025-01-10\"],[112.3114467678052,107.8921549245735,107.4884504805814,100.5747646401079,108.4295052693808,101.9985915359134,114.5117130990463,95.39840021619115,72.25533089682037,100.5648900937107],[\"Wed\",\"Thu\",\"Fri\",\"Sat\",\"Sun\",\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\"],[\"Jan\",\"Jan\",\"Jan\",\"Jan\",\"Jan\",\"Jan\",\"Jan\",\"Jan\",\"Jan\",\"Jan\"],[2025,2025,2025,2025,2025,2025,2025,2025,2025,2025],[0,0,0,0,0,0,0,0,0,0],[1,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>id<\\/th>\\n      <th>lat<\\/th>\\n      <th>lon<\\/th>\\n      <th>date<\\/th>\\n      <th>target<\\/th>\\n      <th>date_dow<\\/th>\\n      <th>date_month<\\/th>\\n      <th>date_year<\\/th>\\n      <th>date_LaborDay<\\/th>\\n      <th>date_NewYearsDay<\\/th>\\n      <th>date_ChristmasDay<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,2,3,5,8,9,10,11]},{\"orderable\":false,\"targets\":0},{\"name\":\" \",\"targets\":0},{\"name\":\"id\",\"targets\":1},{\"name\":\"lat\",\"targets\":2},{\"name\":\"lon\",\"targets\":3},{\"name\":\"date\",\"targets\":4},{\"name\":\"target\",\"targets\":5},{\"name\":\"date_dow\",\"targets\":6},{\"name\":\"date_month\",\"targets\":7},{\"name\":\"date_year\",\"targets\":8},{\"name\":\"date_LaborDay\",\"targets\":9},{\"name\":\"date_NewYearsDay\",\"targets\":10},{\"name\":\"date_ChristmasDay\",\"targets\":11}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n\n\n## Lag\n\nFor time-dependent data, the current value may depend on previous time steps.\nLag transformations create new variables such as lag-1, lag-7, or lag-30.\nRecipes supports this through `step_lag`, which is especially useful in time-series prediction tasks.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec_TimeSpat <- recipe(target ~ ., data = df_TimeSpat)  |> \n  step_lag(target, lag = 3)\nbake(prep(rec_TimeSpat), new_data = df_TimeSpat) |> head(100) |> DT::datatable()\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"datatables html-widget html-fill-item\" id=\"htmlwidget-6b51487b9d667d8c27d3\" style=\"width:100%;height:auto;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-6b51487b9d667d8c27d3\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"],[1,2,3,4,5,6,7,8,9,10],[52.52,48.85,51.51,40.71,34.05,35.68,55.75,37.77,41.9,59.33],[13.4,2.35,-0.13,-74.01000000000001,-118.25,139.69,37.62,-122.42,12.49,18.07],[\"2025-01-01\",\"2025-01-02\",\"2025-01-03\",\"2025-01-04\",\"2025-01-05\",\"2025-01-06\",\"2025-01-07\",\"2025-01-08\",\"2025-01-09\",\"2025-01-10\"],[112.3114467678052,107.8921549245735,107.4884504805814,100.5747646401079,108.4295052693808,101.9985915359134,114.5117130990463,95.39840021619115,72.25533089682037,100.5648900937107],[null,null,null,112.3114467678052,107.8921549245735,107.4884504805814,100.5747646401079,108.4295052693808,101.9985915359134,114.5117130990463]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>id<\\/th>\\n      <th>lat<\\/th>\\n      <th>lon<\\/th>\\n      <th>date<\\/th>\\n      <th>target<\\/th>\\n      <th>lag_3_target<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,2,3,5,6]},{\"orderable\":false,\"targets\":0},{\"name\":\" \",\"targets\":0},{\"name\":\"id\",\"targets\":1},{\"name\":\"lat\",\"targets\":2},{\"name\":\"lon\",\"targets\":3},{\"name\":\"date\",\"targets\":4},{\"name\":\"target\",\"targets\":5},{\"name\":\"lag_3_target\",\"targets\":6}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n\n\n\n## Missing values imputation\n\nAlthough missing values—especially in time-series or spatial data—should ideally be treated during the EDA phase, `recipes` still offers convenient imputation options:\n\n* `step_impute_knn`: k-nearest neighbour imputation\n* `step_impute_linear`: linear interpolation\n* `step_impute_roll`: rolling window based filling\n\nThese steps integrate seamlessly into modelling pipelines, but it remains good practice to address outliers and missing values as early as possible during EDA for better control and transparency.\n\n\n\n\n\n\n\n",
    "supporting": [
      "ml_feature_engineering_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../site_libs/htmltools-fill-0.5.8.1/fill.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/htmlwidgets-1.6.4/htmlwidgets.js\"></script>\n<link href=\"../site_libs/datatables-css-0.0.0/datatables-crosstalk.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/datatables-binding-0.34.0/datatables.js\"></script>\n<script src=\"../site_libs/jquery-3.6.0/jquery-3.6.0.min.js\"></script>\n<link href=\"../site_libs/dt-core-1.13.6/css/jquery.dataTables.min.css\" rel=\"stylesheet\" />\n<link href=\"../site_libs/dt-core-1.13.6/css/jquery.dataTables.extra.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/dt-core-1.13.6/js/jquery.dataTables.min.js\"></script>\n<link href=\"../site_libs/crosstalk-1.2.2/css/crosstalk.min.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/crosstalk-1.2.2/js/crosstalk.min.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}