{
  "hash": "f985d5838a2c53d42420e13de76b064d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Values Extract\nexecute:\n  warning: false\n  error: false\nsidebar:\n  contents: auto\nnumber-sections: true\n---\n\n\n\n\n# Overview and Data\n\nSpatial data extraction is the process of obtaining meaningful information from spatial datasets based on their geographic position. It is used whenever we want to retrieve values from a raster at specific locations, summarize information inside a polygon, mask a raster by an area, or link attributes between different spatial layers. In general, spatial extraction can be divided into two major groups: **raster data extraction** and **vector data extraction**.\n\nSpatial data extraction is especially important when we need to aggregate basic information for specific regions, or when we need to obtain consistent information from different spatial layers for comparison or further analysis.\n\nIn this exercis, we will work with the R package `terra`, which provides efficient tools for handling raster and vector spatial data. For visualization, we will use the `tidyterra` package, which allows `terra` objects to be plotted within the familiar `ggplot2` framework.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load packages\nlibrary(terra)\nlibrary(tidyterra)\nlibrary(tidyverse)\ntheme_set(theme_bw())\nlibrary(patchwork)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ncolor_RUB_blue <- \"#17365c\"\ncolor_RUB_green <- \"#8dae10\"\ncolor_TUD_middleblue <- \"#006ab2\"\ncolor_TUD_lightblue <- \"#009de0\"\ncolor_TUD_green <- \"#007d3f\"\ncolor_TUD_lightgreen <- \"#69af22\"\ncolor_TUD_orange <- \"#ee7f00\"\ncolor_TUD_pink <- \"#EC008D\"\ncolor_TUD_purple <- \"#54368a\"\ncolor_TUD_redpurple <- \"#93107d\"\ncolor_SafetyOrange <- \"#ff5e00\"\ncolor_DRESDEN <- c(\"#03305D\", \"#28618C\", \"#539DC5\", \"#84D1EE\", \"#009BA4\", \"#13A983\", \"#93C356\", \"#BCCF02\")\n```\n:::\n\n\n\n\n\nFor the exercises, we will use simple synthetic datasets with random locations and values:\n\n1. Two polygons used as extraction masks  \n2. An original raster with 1° spatial resolution  \n3. A set of points  \n4. A set of polygons\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrst_Random  <- rast(\"https://raw.githubusercontent.com/HydroSimul/Web/refs/heads/main/data_share/rst_Extract_Random.asc\")\nnames(rst_Random) <- \"RandomValues\"\nvct_Grid    <- vect(\"https://raw.githubusercontent.com/HydroSimul/Web/refs/heads/main/data_share/vct_Extract_Grid.geojson\")\nvct_Region    <- vect(\"https://raw.githubusercontent.com/HydroSimul/Web/refs/heads/main/data_share/vct_Extract_Region.geojson\")\nvct_Point   <- vect(\"https://raw.githubusercontent.com/HydroSimul/Web/refs/heads/main/data_share/vct_Extract_Point.geojson\")\nvct_Voronoi <- vect(\"https://raw.githubusercontent.com/HydroSimul/Web/refs/heads/main/data_share/vct_Extract_Voronoi.geojson\")\n```\n:::\n\n::: {.cell fig-fullwidth='true'}\n\n```{.r .cell-code  code-fold=\"true\"}\ngp_Raster <- ggplot() +\n  geom_spatraster(data = rst_Random) +\n  geom_spatvector(data = vct_Grid, fill = NA, color = \"gray86\") +\n  geom_spatvector_text(data = vct_Grid, aes(label = lyr.1), color = \"gray86\") +\n  geom_spatvector(data = vct_Region, color = color_TUD_pink, linewidth = .5, fill = NA) +\n  scale_fill_gradientn(\"Value\", \n                       colors = color_DRESDEN,\n                       limits = c(1, 100)) +\n  ggtitle(\"Raster\") +\n  coord_sf(xlim = c(0, 5), ylim = c(0, 5), expand = FALSE) +\n  theme(axis.title = element_blank(),\n        axis.text.y = element_text(angle = 90, hjust = .5))\n\n\ngp_Polygon <- ggplot() +\n  geom_spatvector(data = vct_Grid, fill = NA, color = \"gray86\") +\n  geom_spatvector_text(data = vct_Grid, aes(label = lyr.1), color = \"gray86\") +\n  geom_spatvector(data = vct_Region, aes(color = Region, fill = Region), alpha = .5) +\n  scale_color_manual(values = c(a = color_RUB_green, b = color_RUB_blue)) +\n  scale_fill_manual(values = c(a = color_RUB_green, b = color_RUB_blue)) +\n  ggtitle(\"Regions\") +\n  coord_sf(xlim = c(0, 5), ylim = c(0, 5), expand = FALSE) +\n  theme(axis.title = element_blank(),\n        axis.text.y = element_text(angle = 90, hjust = .5))\n\ngp_Point <- ggplot() +\n  geom_spatvector(data = vct_Point, aes(fill = Values),\n                  shape = 24, size = 4) +\n  geom_spatvector(data = vct_Region, color = color_TUD_pink, linewidth = .5, fill = NA) +\n  scale_fill_gradientn(\"Value\", \n                       colors = color_DRESDEN, \n                       na.value = \"transparent\",\n                       limits = c(1, 100)) +\n  ggtitle('Point') +\n  coord_sf(xlim = c(0, 5), ylim = c(0, 5), expand = FALSE) +\n  theme(axis.title = element_blank(),\n        axis.text.y = element_text(angle = 90, hjust = .5))\n\ngp_Voronoi <- ggplot() +\n  geom_spatvector(data = vct_Voronoi, aes(fill = Values)) +\n  geom_spatvector(data = vct_Region, color = color_TUD_pink, linewidth = .5, fill = NA) +\n  scale_fill_gradientn(\"Value\", \n                       colors = color_DRESDEN, \n                       na.value = \"transparent\",\n                       limits = c(1, 100)) +\n  ggtitle('Polygon') +\n  coord_sf(xlim = c(0, 5), ylim = c(0, 5), expand = FALSE) +\n  theme(axis.title = element_blank(),\n        axis.text.y = element_text(angle = 90, hjust = .5))\n\n# Combine plots\n((gp_Polygon + theme(axis.text.x = element_blank())) | (gp_Raster + theme(axis.text.x = element_blank(), axis.text.y = element_blank()))) / (gp_Point | (gp_Voronoi + theme(axis.text.y = element_blank()))) + plot_layout(guides = \"collect\")\n```\n\n::: {.cell-output-display}\n![](spatial_extract_files/figure-html/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n\n\n\n\n# Extract from Raster\n\nRaster data can be understood as sampled representations of a continuous geographic surface, where the study area is divided into a regular grid of equally sized cells. Typical raster datasets, such as elevation models, are fundamental in many spatial research fields. Meteorological variables, including temperature and precipitation, are also commonly provided in raster form, as this structure allows spatially distributed values to be represented in a consistent way.\n\nIn many applications such as hydrologcial modelling we often need to derive statistical summaries for specific regions, for example regional averages or aggregated indicators. \n\nTo perform an **EXTRACT** operation, two components are required: the **raster dataset** and the **regions of interest** (usually provided as vector polygons). Before extraction, it is essential to confirm that both datasets share the same coordinate reference system (CRS). In this exercis, we focus on the concepts and principles behind raster extraction. Four methods will be introduced and discussed.\n\n## Rough with original resolution\n\nThe first method uses the raster at its **original resolution**. However, when the spatial resolution is coarse, the selected grid cells may not accurately represent the region of interest. This is a common issue in meteorological data, where spatial resolution is often relatively low because temporal resolution is prioritized over fine spatial detail.\n\n\nFor the **SELECT** operation, two common methods are used: `Touch` and `Center-point`.\n\n- `Touch`: all grid cells that intersect the region are selected.  \n- `Center-point`: only grid cells whose center point falls within the region are selected.\n\nBoth methods, however, can produce *implausible* cases:\n\n1. Using `Touch`, cells with only a small portion inside the region (e.g., Cell 4) are still selected.  \n2. Using `Center-point`, a cell with a small fraction inside the region (e.g., Cell 5, one-eighth) is counted as a full cell, while a cell with most of its area inside the region (e.g., Cell 18, three-quarters) may be ignored if its center lies outside.\n\nIn summary, using the original raster resolution is reasonable only when the mismatch between grid cells and region boundaries is small.  \n\n- `Touch` is suitable for extreme statistics, such as maximum or minimum values, because it includes all intersecting cells.  \n- `Center-point` is generally better for calculating averages, as the over-selection and under-selection at the boundaries can balance out, reducing deviation.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Apply a mask to 'rst_Random' using the second polygon in 'vct_Region'\n# 'touches = TRUE' means that cells that **touch the polygon boundary** will also be included\nrst_CropTouch <- mask(rst_Random, vct_Region[2], touches = TRUE)\n\n# Calculate the global mean of the masked raster 'rst_CropTouch'\n# 'na.rm = TRUE' ensures that NA values are ignored in the calculation\nglobal(rst_CropTouch, fun = mean, na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 mean\nRandomValues 43.21053\n```\n\n\n:::\n\n```{.r .cell-code}\n# Apply a mask to 'rst_Random' using the second polygon in 'vct_Region'\n# 'touches = FALSE' means that **only cells fully inside** the polygon are included\nrst_CropCenter <- mask(rst_Random, vct_Region[2], touches = FALSE)\n\n# Calculate the global mean of the masked raster 'rst_CropCenter'\n# Again, NA values are ignored\nglobal(rst_CropCenter, fun = mean, na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             mean\nRandomValues   47\n```\n\n\n:::\n:::\n\n::: {.cell fig-fullwidth='true'}\n\n```{.r .cell-code  code-fold=\"true\"}\ngp_CropTouch <- ggplot() +\n  geom_spatraster(data = rst_CropTouch) +\n  geom_spatvector(data = vct_Region[2], color = color_TUD_pink, linewidth = .5, fill = NA) +\n  scale_fill_gradientn(\"Value\", \n                       colors = color_DRESDEN, \n                       na.value = \"transparent\",\n                       limits = c(1, 100)) +\n  ggtitle('Mask with \"Touch\"') +\n  coord_sf(xlim = c(0, 5), ylim = c(0, 5), expand = FALSE) +\n  theme(axis.title = element_blank(),\n        axis.text.y = element_text(angle = 90, hjust = .5))\n\ngp_CropCenter <- ggplot() +\n  geom_spatraster(data = rst_CropCenter) +\n  geom_spatvector(data = vct_Region[2], color = color_TUD_pink, linewidth = .5, fill = NA) +\n  geom_spatvector_text(data = vct_Grid[c(5, 18)], aes(label = lyr.1), color = color_TUD_pink) +\n  scale_fill_gradientn(\"Value\", \n                       colors = color_DRESDEN, \n                       na.value = \"transparent\",\n                       limits = c(1, 100)) +\n  ggtitle('Mask with \"Center\"') +\n  coord_sf(xlim = c(0, 5), ylim = c(0, 5), expand = FALSE) +\n  theme(axis.title = element_blank(),\n        axis.text.y = element_text(angle = 90, hjust = .5))\n\n\n(gp_CropTouch | gp_CropCenter) + plot_layout(guides = \"collect\")\n```\n\n::: {.cell-output-display}\n![](spatial_extract_files/figure-html/unnamed-chunk-6-1.png){width=960}\n:::\n:::\n\n\n\n\n\n\n## Refine Resolution\n\nThe second method is straightforward: we increase the raster resolution, for example by making it 10 times finer in each dimension, which results in 100 times more grid cells overall.\n\nConceptually, this method does not differ from the first method, but it helps to reduce the mismatch between grid cells and the region of interest. This approach is particularly useful when using software that lacks dedicated spatial analysis tools—such as Matlab without the Spatial Analysis Toolbox. By simply refining the raster (e.g., replicating each cell 10 times in both rows and columns), we can achieve a finer resolution without relying on specialized spatial functions.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Disaggregate the raster 'rst_Random' by a factor of 10\n# This increases the resolution, creating smaller cells (finer raster)\nrst_Disagg <- disagg(rst_Random, 10)\n\n# Mask the disaggregated raster using the second polygon in 'vct_Region'\n# 'touches = TRUE' includes cells that touch the polygon boundary\nrst_CropTouch_Disagg <- mask(rst_Disagg, vct_Region[2], touches = TRUE)\n\n# Calculate the global mean of the masked raster\n# 'na.rm = TRUE' ensures missing values are ignored\nglobal(rst_CropTouch_Disagg, fun = mean, na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 mean\nRandomValues 47.21555\n```\n\n\n:::\n\n```{.r .cell-code}\n# Mask the disaggregated raster using the second polygon\n# 'touches = FALSE' includes only cells completely inside the polygon\nrst_CropCenter_Disagg <- mask(rst_Disagg, vct_Region[2], touches = FALSE)\n\n# Calculate the global mean of the masked raster\nglobal(rst_CropCenter_Disagg, fun = mean, na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 mean\nRandomValues 47.76703\n```\n\n\n:::\n:::\n\n::: {.cell fig-fullwidth='true'}\n\n```{.r .cell-code  code-fold=\"true\"}\ngp_CropTouch_Disagg <- ggplot() +\n  geom_spatraster(data = rst_CropTouch_Disagg) +\n  geom_spatvector(data = vct_Region[2], color = color_TUD_pink, linewidth = .5, fill = NA) +\n  scale_fill_gradientn(\"Value\", \n                       colors = color_DRESDEN, \n                       na.value = \"transparent\",\n                       limits = c(1, 100)) +\n  ggtitle('Mask with \"Touch\" (disaggregated raster)') +\n  coord_sf(xlim = c(0, 5), ylim = c(0, 5), expand = FALSE) +\n  theme(axis.title = element_blank(),\n        axis.text.y = element_text(angle = 90, hjust = .5))\n\ngp_CropCenter_Disagg <- ggplot() +\n  geom_spatraster(data = rst_CropCenter_Disagg) +\n  geom_spatvector(data = vct_Region[2], color = color_TUD_pink, linewidth = .5, fill = NA) +\n  geom_spatvector_text(data = vct_Grid[c(5, 18)], aes(label = lyr.1), color = color_TUD_pink) +\n  scale_fill_gradientn(\"Value\", \n                       colors = color_DRESDEN, \n                       na.value = \"transparent\",\n                       limits = c(1, 100)) +\n  ggtitle('Mask with \"Center\" (disaggregated raster)') +\n  coord_sf(xlim = c(0, 5), ylim = c(0, 5), expand = FALSE) +\n  theme(axis.title = element_blank(),\n        axis.text.y = element_text(angle = 90, hjust = .5))\n\n\n(gp_CropTouch_Disagg | gp_CropCenter_Disagg) + plot_layout(guides = \"collect\")\n```\n\n::: {.cell-output-display}\n![](spatial_extract_files/figure-html/unnamed-chunk-8-1.png){width=960}\n:::\n:::\n\n\n\n\n\n\nAs illustrated in the figure, the accuracy is significantly improved, and the deviation is expected to remain below 1%.\n\n\n## Exact Extraction with Polygons\n\nThe weighted mean generally provides more accurate results than a simple numerical average. In spatial analysis, the key aspect of a weighted mean is the choice of weights, which are typically based on the proportion of each grid cell's area within the region of interest. Therefore, the main task in this method is to calculate the area of each raster value that lies within the target region.\n\nTo perform this calculation, it is often necessary to **convert raster cells into vector polygons**. There are two common approaches:\n\n- Assign all cells with the same value to a single polygon. This method is convenient for categorical data with only a few distinct values.  \n- Convert each raster cell into an individual rectangle polygon and calculate the **proportion of its area** that falls within the region. This method is implemented in the `terra` package in R. However, a small deviation can occur when using longitude-latitude coordinates (CRS), because the actual area of each grid cell is not uniform, leading to minor inaccuracies in the weight calculation.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Convert the raster 'rst_Random' into polygons\n# Each raster cell becomes a polygon\nvct_Random <- as.polygons(rst_Random)\n\n# Intersect the raster polygons with the first polygon in 'vct_Region'\n# Only the parts of 'vct_Random' that overlap with 'vct_Region[1]' are kept\nvct_Random_Poly1 <- terra::intersect(vct_Random, vct_Region[1])\n\n# Intersect the raster polygons with the second polygon in 'vct_Region'\n# Only the parts of 'vct_Random' that overlap with 'vct_Region[2]' are kept\nvct_Random_Poly2 <- terra::intersect(vct_Random, vct_Region[2])\n\n# Calculate the mean value of the attribute 'RandomValues' in the first intersected polygon\n# 'RandomValues' comes from the original raster values when it was converted to polygons\nmean(vct_Random_Poly1$RandomValues)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 49.77778\n```\n\n\n:::\n\n```{.r .cell-code}\n# Calculate the mean value of the attribute 'RandomValues' in the second intersected polygon\nmean(vct_Random_Poly2$RandomValues)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 43.21053\n```\n\n\n:::\n:::\n\n::: {.cell fig-fullwidth='true'}\n\n```{.r .cell-code  code-fold=\"true\"}\ngp_CropExact_Poly1 <- ggplot() +\n  geom_spatvector(data = vct_Random_Poly1, aes(fill = RandomValues)) +\n  geom_spatvector(data = vct_Region[1], color = color_TUD_pink, linewidth = .5, fill = NA) +\n  scale_fill_gradientn(\"Value\", \n                       colors = color_DRESDEN, \n                       na.value = \"transparent\",\n                       limits = c(1, 100)) +\n  ggtitle('Mask with vector-cell') +\n  coord_sf(xlim = c(0, 5), ylim = c(0, 5), expand = FALSE) +\n  theme(axis.title = element_blank(),\n        axis.text.y = element_text(angle = 90, hjust = .5))\ngp_CropExact_Poly2 <- ggplot() +\n  geom_spatvector(data = vct_Random_Poly2, aes(fill = RandomValues)) +\n  geom_spatvector(data = vct_Region[2], color = color_TUD_pink, linewidth = .5, fill = NA) +\n  scale_fill_gradientn(\"Value\", \n                       colors = color_DRESDEN, \n                       na.value = \"transparent\",\n                       limits = c(1, 100)) +\n  ggtitle('Mask with vector-cell') +\n  coord_sf(xlim = c(0, 5), ylim = c(0, 5), expand = FALSE) +\n  theme(axis.title = element_blank(),\n        axis.text.y = element_text(angle = 90, hjust = .5))\n\n\n(gp_CropExact_Poly1 | gp_CropExact_Poly2) + plot_layout(guides = \"collect\")\n```\n\n::: {.cell-output-display}\n![](spatial_extract_files/figure-html/unnamed-chunk-10-1.png){width=960}\n:::\n:::\n\n\n\n\n\nIn the illustration, each raster value has been converted into a single polygon with the same value.\n\n\nHere’s a polished, academic version of your section in R Markdown style:\n\n## Exact Extraction with Scale Product\n\nThis method is designed specifically for meteorological data that span **large temporal scales**. It is also the most efficient method in practice.\n\nThe theory and formulation can be expressed as:\n\n$$\n\\vec{\\Omega}_{[time, region]} = \\vec{A}_{[time, grid]} \\cdot \\vec{W}_{[grid, region]}\n$$\n\nWhere:  \n\n- $\\vec{\\Omega}_{[time, region]}$ = values for each region over time  \n- $\\vec{A}_{[time, grid]}$ = matrix of all values for each grid over time [time, grid]  \n- $\\vec{W}_{[grid, region]}$ = weight matrix representing the contribution of each grid to each region [grid, region]  \n\n### Weight Matrix\n\nThe weights are calculated as the proportion of each grid cell that lies within a region relative to the **total area of the region**. Note that this considers only the portion of the grid inside the region, not the entire grid.\n\nExample weight matrix (`weight_grid`):\n\n``` r\n            [R1]      [R2]\n [G1]      0.000      0.00\n [G2] 134364.119 189431.77\n [G3] 212464.416      0.00\n [G4]   2747.413      0.00\n [G5] 150176.618      0.00\n [G6]      0.000  45011.22\n```\n\n`G` represents grid cells and `R` represents regions.\n\n### Value Matrix\n\nExample of a value matrix (`mat_value`):\n\n```r\n     [G1] [G2] [G3] [G4] [G5] [G6] \n[T1]    2    1    3    4    1    1  \n[T2]    3    1    2    4    1    1  \n```\n\n`T` represents time steps.\n\nBy multiplying the value matrix by the weight matrix, we obtain the weighted regional values over time. This approach is particularly effective for large-scale temporal datasets.\n\n\n# Extract from Vector Data\n\nCompared to raster data, **vector data** represent spatial information using various geometric shapes. The three basic (and most common) vector forms are **Points**, **Lines**, and **Polygons**. In all cases, the **geometry** of these data structures is defined by sets of coordinate pairs (x, y) ([terra reference](https://rspatial.org/terra/spatial/2-spatialdata.html#vector-data)). The geometry specifies the location and topology, while the other important component of vector data is the **attributes** associated with each shape, where the actual data values are stored.\n\nIn hydrology or meteorology, vector data are often in the form of point data (e.g., measurements from stations) or area data (e.g., land use or soil type). Line data, such as isolines, are less commonly used for storing values and are typically used for visualization purposes. Therefore, the **EXTRACT** operation for vector data usually involves summarizing attribute values for specific regions.\n\nIn this lecture, we will focus on **POINT** and **POLYGON** vector data.\n\n## Extract from Polygons\n\nWhen extracting a single attribute value, we can use the function `intersect()` to find the overlap between the data polygons and the region polygons. After the intersection, statistical summaries (e.g., mean, sum, or count) can be calculated for each region.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Intersect the Voronoi polygons with the second polygon in 'vct_Region'\n# Only the parts of 'vct_Voronoi' that overlap with 'vct_Region[2]' are kept\nvct_Voronoi_Poly2 <- terra::intersect(vct_Voronoi, vct_Region[2])\n\n# Calculate the mean value of the attribute 'Values' in the second intersected polygon\nmean(vct_Voronoi_Poly2$Values)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 42.26673\n```\n\n\n:::\n:::\n\n::: {.cell fig-fullwidth='true'}\n\n```{.r .cell-code  code-fold=\"true\"}\ngp_CropVoronoi_Poly2 <- ggplot() +\n  geom_spatvector(data = vct_Voronoi_Poly2, aes(fill = Values)) +\n  geom_spatvector(data = vct_Region[2], color = color_TUD_pink, linewidth = .5, fill = NA) +\n  scale_fill_gradientn(\"Value\", \n                       colors = color_DRESDEN, \n                       na.value = \"transparent\",\n                       limits = c(1, 100)) +\n  ggtitle('Mask with polygons') +\n  coord_sf(xlim = c(0, 5), ylim = c(0, 5), expand = FALSE) +\n  theme(axis.title = element_blank(),\n        axis.text.y = element_text(angle = 90, hjust = .5))\n\n\n(gp_Voronoi | gp_CropVoronoi_Poly2) + plot_layout(guides = \"collect\")\n```\n\n::: {.cell-output-display}\n![](spatial_extract_files/figure-html/unnamed-chunk-12-1.png){width=960}\n:::\n:::\n\n\n\n\n\n\nWhen we need to extract multiple attributes simultaneously, we can apply the same concept as in the previous section [Exact with Scale Product]():\n\n$$\n\\vec{\\Omega}_{[attribute, region]} = \\vec{A}_{[attribute, polygon]} \\cdot \\vec{W}_{[polygon, region]}\n$$\n\nWhere:  \n\n- $\\vec{\\Omega}_{[attribute, region]}$ = values for each region for all attributes  \n- $\\vec{A}_{[attribute, polygon]}$ = matrix of attribute values for each polygon [attribute, polygon]  \n- $\\vec{W}_{[polygon, region]}$ = weight matrix representing the contribution of each polygon to each region [polygon, region]  \n\nThe procedure consists of three main steps:\n\n1. **Weight-Matrix creation**: Use `intersect()` to calculate the proportion of each polygon that lies within each region, forming the matrix [polygon, region].  \n2. **Value-Matrix creation**: Compile the attribute values of all polygons into a matrix [attribute, polygon].  \n3. **Scale product**: Multiply the Value-Matrix by the Weight-Matrix to obtain the weighted attribute values for each region.\n\n\n\n\n\n\n\n## Extract from Points\n\n### Numerical Mean\n\nThe simplest and most direct method is to calculate the **numerical mean** of all points located within a given region:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Intersect the point vector with the second polygon in 'vct_Region'\n# Only points that fall inside 'vct_Region[2]' are kept\nvct_Point_Poly2 <- terra::intersect(vct_Point, vct_Region[2])\n\n# Calculate the mean value of the attribute 'Values' in the second intersected polygon\nmean(vct_Point_Poly2$Values)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 63.80587\n```\n\n\n:::\n:::\n\n::: {.cell fig-fullwidth='true'}\n\n```{.r .cell-code  code-fold=\"true\"}\ngp_CropPoint_Poly2 <- ggplot() +\n  geom_spatvector(data = vct_Point_Poly2, aes(fill = Values),\n                  shape = 24, size = 4) +\n  geom_spatvector(data = vct_Region[2], color = color_TUD_pink, linewidth = .5, fill = NA) +\n  scale_fill_gradientn(\"Value\", \n                       colors = color_DRESDEN, \n                       na.value = \"transparent\",\n                       limits = c(1, 100)) +\n  ggtitle('Mask with polygons') +\n  coord_sf(xlim = c(0, 5), ylim = c(0, 5), expand = FALSE) +\n  theme(axis.title = element_blank(),\n        axis.text.y = element_text(angle = 90, hjust = .5))\n\n\n(gp_Point | gp_CropPoint_Poly2) + plot_layout(guides = \"collect\")\n```\n\n::: {.cell-output-display}\n![](spatial_extract_files/figure-html/unnamed-chunk-14-1.png){width=960}\n:::\n:::\n\n\n\n\n\nThe procedure for calculating the numerical mean consists of two steps:\n\n1. Intersect the points with the regions, selecting only those points that fall within each region.  \n2. Calculate the mean value of the selected points for each region.\n\nThe limitations of this approach are clear: points located near the boundaries of a region may be ignored, and some regions may contain no points at all. \n\nTo overcome these issues, point data can be converted into **polygon** form (e.g., Thiessen polygons) or **raster** form (via interpolation), and then analyzed using the extraction methods described earlier. For more details, see [Spatial Interpolation](spatial_interpolate.qmd).\n\n\n",
    "supporting": [
      "spatial_extract_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}