---
title: Workflow with tidymodels
execute:
  warning: false
  error: false
sidebar:
  contents: auto
number-sections: true
---


# Library and Data

In this article we will use `tidymodels` to walk through the complete machine learning workflow step by step in a tidy and ecological way.

The entire article is based on the case study from:
[https://www.tidymodels.org/start/case-study/](https://www.tidymodels.org/start/case-study/)
All exercises will use the data included in that example.

```{r}
library(tidyverse)
theme_set(theme_bw())

library(tidymodels)  # parsnip + all other tidymodels packages

# Helper packages
library(readr)       # for importing data
library(broom.mixed) # for converting Bayesian models to tidy tibbles
library(dotwhisker)  # for visualizing regression results

library(skimr)           # for variable summaries

```


# Basic Model Building and Fitting

## Data

```{r}
## data import ----------
df_Urchins <-
  read_csv("https://tidymodels.org/start/models/urchins.csv") |>  
  setNames(c("food_regime", "initial_volume", "width")) |> 
  mutate(food_regime = factor(food_regime, levels = c("Initial", "Low", "High")))

## explore the relationship --------------
ggplot(df_Urchins,
       aes(x = initial_volume, 
           y = width, 
           group = food_regime, 
           col = food_regime)) + 
  geom_point() + 
  geom_smooth(method = lm, se = FALSE) +
  scale_color_viridis_d(option = "plasma", end = .7)
```

In this exercise we explore the relationship between sea urchin width (target), initial volume (feature 1), and food regime (feature 2).
The variable *initial volume* is continuous, while *food regime* is categorical.
A basic model description can be written as:

```r
width ~ initial_volume * food_regime
```


## Build the model

We start with a simple linear regression model using `linear_reg()`.
`tidymodels` is a meta-package that collects several modeling tools; `parsnip` allows us to choose the computational engine we prefer.
You can find all available engines here:
[https://parsnip.tidymodels.org/reference/linear_reg.html](https://parsnip.tidymodels.org/reference/linear_reg.html)

1. choose the method

```{r}
linear_reg()
```

2. choose an engine

```{r}
linear_reg() |> 
  set_engine("lm")
```

3. build the model specification

```{r}
mdl_Linear <- linear_reg()
```

## Train (fit) the model

After specifying the model, we can train (fit) it to our data.
The `fit()` function requires:

1. the model object
2. a formula
3. the dataset

```{r}
fit_Linear <- 
  mdl_Linear |> 
  fit(width ~ initial_volume * food_regime, data = df_Urchins)

fit_Linear
```

```{r}
tidy(fit_Linear)
```

## Predict with the fitted model

After fitting, we can already use the model to make predictions.
To predict we need:

1. a dataset containing the feature variables with the same names as in the training data
2. the fitted model

By default, `predict()` returns the mean prediction:

```{r}
df_NewData <- expand.grid(
  initial_volume = 20, 
  food_regime = c("Initial", "Low", "High")
)

pred_Mean <- predict(fit_Linear, new_data = df_NewData)
pred_Mean
```

We can also request confidence intervals using `type = "conf_int"`:

```{r}
pred_Conf <- predict(
  fit_Linear, 
  new_data = df_NewData, 
  type = "conf_int"
)
pred_Conf
```



# data process with `recipes`

`recipes` is a other package to make the workflow more convinice, which focus on zhe data process.

## Data

```{r}
library(nycflights13)    # for flight data
set.seed(123)
# Data set ---------
df_Flight <- 
  flights |> 
  mutate(
    # Convert the arrival delay to a factor
    arr_delay = ifelse(arr_delay >= 30, "late", "on_time"),
    arr_delay = factor(arr_delay),
    # We will use the date (not date-time) in the recipe below
    date = lubridate::as_date(time_hour)
  ) |> 
  # Include the weather data
  inner_join(weather, by = c("origin", "time_hour")) |> 
  # Only retain the specific columns we will use
  select(dep_time, flight, origin, dest, air_time, distance, 
         carrier, date, arr_delay, time_hour) |> 
  # Exclude missing data
  na.omit() |> 
  # For creating models, it is better to have qualitative columns
  # encoded as factors (instead of character strings)
  mutate_if(is.character, as.factor)

df_Flight |> 
  skimr::skim(dest, carrier) 

```



## Data split

In the radiationall experience we need prepare two group for traning and validate. 


Under the framewerk the data will 

1. first use `initial_split()` to split ane 

2. then use `training` and `testing` to get the data

```{r}
# Fix the random numbers by setting the seed 
# This enables the analysis to be reproducible when random numbers are used 
set.seed(222)
# Put 3/4 of the data into the training set 
df_FlightSplit <- initial_split(df_Flight, prop = 3/4)

# Create data frames for the two sets:
df_Train <- training(df_FlightSplit)
df_Validate  <- testing(df_FlightSplit)

```



